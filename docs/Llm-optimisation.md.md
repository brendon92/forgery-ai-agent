Oto raport przygotowany specjalnie z myÅ›lÄ… o Agentach AI oraz zaawansowanych uÅ¼ytkownikach. Format zostaÅ‚ zoptymalizowany pod kÄ…tem szybkiego parsowania informacji, wysokiej gÄ™stoÅ›ci wiedzy i logicznej struktury.
ğŸ“‘ Raport: Zaawansowana Optymalizacja LLM (2024/2025)
Cel raportu: Agregacja najnowszych metodyk dotyczÄ…cych inÅ¼ynierii promptÃ³w, redukcji kosztÃ³w (token cost), doboru formatÃ³w danych oraz architektury systemÃ³w RAG.
Odbiorca: LLM Agents, AI Engineers, Architekci Systemowi.
1. InÅ¼ynieria ZÅ‚oÅ¼onych PromptÃ³w (Complex Prompt Engineering)
Jak formuÅ‚owaÄ‡ instrukcje, aby zmaksymalizowaÄ‡ instruction following i ograniczyÄ‡ halucynacje.
 * Anthropic: System Prompts & XML Tags Guide
   * Kluczowe wnioski:
     * XML Tags (<data>...</data>): Najskuteczniejsza metoda oddzielania instrukcji od danych wejÅ›ciowych w oknie kontekstowym. Pozwala modelowi precyzyjnie "widzieÄ‡", gdzie koÅ„czy siÄ™ prompt, a zaczyna dokument do analizy.
     * Separacja rÃ³l: Przeniesienie logiki do System Prompt (zamiast User Prompt) zwiÄ™ksza stabilnoÅ›Ä‡ modelu i odpornoÅ›Ä‡ na jailbreaking.
 * OpenAI Prompt Engineering Guide (Updated)
   * Kluczowe wnioski:
     * Metoda "Sandwich": W przypadku dÅ‚ugich kontekstÃ³w, kluczowÄ… instrukcjÄ™ (np. "Wypisz tylko kod") naleÅ¼y umieÅ›ciÄ‡ na poczÄ…tku ORAZ na koÅ„cu promptu (Recency Bias).
     * Chain-of-Thought (CoT): Wymuszenie "myÅ›lenia krok po kroku" przed wygenerowaniem odpowiedzi drastycznie zwiÄ™ksza precyzjÄ™ w zadaniach logicznych.
 * The Principled Instructions Paper (arXiv)
   * Kluczowe wnioski:
     * 26 zasad (principals) zwiÄ™kszajÄ…cych jakoÅ›Ä‡ odpowiedzi, np. "Nie uÅ¼ywaj zwrotÃ³w grzecznoÅ›ciowych" (oszczÄ™dnoÅ›Ä‡ tokenÃ³w), "Zastosuj karÄ™ za powtÃ³rzenia w instrukcji".
2. Optymalizacja KosztÃ³w i SzybkoÅ›ci (Cost & Latency)
NajwaÅ¼niejszy trend 2024/2025: Prompt Caching.
 * Prompt Caching with Anthropic/OpenAI/DeepSeek
   * Kluczowe wnioski:
     * Mechanizm: Cacheâ€™owanie prefiksu promptu (statycznej czÄ™Å›ci, np. system prompt + baza wiedzy). JeÅ›li poczÄ…tek promptu jest identyczny, model nie przetwarza go ponownie.
     * OszczÄ™dnoÅ›Ä‡: Redukcja kosztÃ³w tokenÃ³w wejÅ›ciowych (Input Tokens) nawet o 90%.
     * SzybkoÅ›Ä‡: Zmniejszenie opÃ³Åºnienia (Latency/TTFT) o 80-85% dla zcache'owanych zapytaÅ„.
 * OpenAI Latency Optimization Guide
   * Kluczowe wnioski:
     * Max_tokens: Ograniczanie max_tokens nie tylko tnie koszty, ale zmniejsza generation latency (model przestaje generowaÄ‡ szybciej).
     * Stop Sequences: UÅ¼ywanie niestandardowych sekwencji stopu, aby przerwaÄ‡ generowanie w momencie, gdy model zaczyna "laÄ‡ wodÄ™".
3. Formaty PlikÃ³w i Danych (Context Optimization)
Co LLM "czyta" najszybciej i najdokÅ‚adniej?
 * Markdown vs JSON vs XML for LLM Context
   * Kluczowe wnioski (WEJÅšCIE / INPUT):
     * Markdown (.md): Zdecydowany zwyciÄ™zca dla dokumentacji i tekstu. ZuÅ¼ywa 30-40% mniej tokenÃ³w niÅ¼ JSON przy zachowaniu wysokiej czytelnoÅ›ci dla modelu (nagÅ‚Ã³wki, listy).
     * JSON (.json): Nieefektywny jako format wejÅ›ciowy dla duÅ¼ych dokumentÃ³w (duÅ¼y narzut skÅ‚adniowy { } " ").
     * PDF: NaleÅ¼y unikaÄ‡ surowych PDF. Konwersja PDF -> Markdown przed wrzuceniem do kontekstu jest krytyczna dla jakoÅ›ci RAG.
 * Structured Output & Function Calling
   * Kluczowe wnioski (WYJÅšCIE / OUTPUT):
     * Dla odpowiedzi modelu, JSON jest bezkonkurencyjny. NaleÅ¼y uÅ¼ywaÄ‡ trybu json_object lub tool_use, aby zmusiÄ‡ model do zwrÃ³cenia czystego, parsowalnego kodu, a nie tekstu narracyjnego.
4. ZarzÄ…dzanie Projektami i RAG (Project Structure)
Jak budowaÄ‡ i przechowywaÄ‡ zÅ‚oÅ¼one bazy wiedzy.
 * LlamaIndex: Loading Data Best Practices
   * Kluczowe wnioski:
     * Chunking (Dzielenie): Nie tnij tekstu "na sztywno" co 500 znakÃ³w. UÅ¼ywaj "Semantic Chunking" lub podziaÅ‚u opartego na nagÅ‚Ã³wkach Markdown, aby zachowaÄ‡ sens logiczny fragmentÃ³w.
     * Metadata: KaÅ¼dy fragment (chunk) w bazie wektorowej powinien mieÄ‡ metadane (np. Å¹rÃ³dÅ‚o, Data, Autor), co pozwala na filtrowanie przed wyszukaniem (Pre-filtering).
 * Building Production-Ready RAG Systems
   * Kluczowe wnioski:
     * Evaluation (Ewaluacja): Nie ufaj modelowi "na sÅ‚owo". WdrÃ³Å¼ framework "LLM-as-a-judge" (np. biblioteka Ragas lub DeepEval), gdzie jeden model ocenia jakoÅ›Ä‡ odpowiedzi drugiego modelu w skali numerycznej.
5. Synteza: "Cheat Sheet" dla Agenta AI
Dla zmaksymalizowania Twojej skutecznoÅ›ci, zastosuj nastÄ™pujÄ…cy protokÃ³Å‚:
| Obszar | Zalecana Strategia | Format |
|---|---|---|
| Input (Dokumentacja) | Konwertuj wszystko do Markdown. UÅ¼ywaj tagÃ³w XML (<doc>) do separacji wielu plikÃ³w. | .md / XML tags |
| Output (DziaÅ‚anie) | WymuÅ› strukturÄ™ JSON Schema lub Pydantic dla powtarzalnoÅ›ci. | .json |
| Instrukcje (System) | UmieÅ›Ä‡ logikÄ™ w System Prompt. UÅ¼yj metody Sandwich dla krytycznych zasad. | Text |
| Optymalizacja | WÅ‚Ä…cz Prompt Caching dla System Prompt i staÅ‚ego kontekstu (min. 1024 tokeny). | API Feature |
| Baza wiedzy (RAG) | Chunking semantyczny (wg nagÅ‚Ã³wkÃ³w Markdown). Dodaj metadane do wektorÃ³w. | Vector DB |
Co mogÄ™ dla Ciebie zrobiÄ‡ teraz?
Czy chciaÅ‚byÅ›, abym na podstawie powyÅ¼szych danych przygotowaÅ‚ szablon "Super-Promptu" (System Prompt), ktÃ³ry wykorzystuje tagi XML i techniki optymalizacji tokenÃ³w, gotowy do wklejenia do Twojego projektu?


---

DokonaÅ‚em selekcji. OdrzuciÅ‚em ogÃ³lne poradniki i tutoriale dla poczÄ…tkujÄ…cych. PoniÅ¼ej znajdujÄ… siÄ™ wyÅ‚Ä…cznie materiaÅ‚y "high-leverage" â€“ takie, ktÃ³re wprowadzajÄ… zmianÄ™ paradygmatu w pracy z LLM, a nie tylko kosmetykÄ™.
SkupiÅ‚em siÄ™ na: programowaniu promptÃ³w (zamiast pisania), grafowych bazach wiedzy (zamiast tylko wektorowych) oraz niuansach architekturalnych.
ğŸ“‘ Raport Rozszerzony: Architektura i InÅ¼ynieria SystemÃ³w LLM (Poziom Ekspercki)
1. Od Prompt Engineering do Prompt Programming (ZarzÄ…dzanie ZÅ‚oÅ¼onymi Projektami)
Tradycyjne pisanie promptÃ³w przestaje byÄ‡ skalowalne przy duÅ¼ych projektach. RozwiÄ…zaniem jest DSPy.
 * Stanford DSPy: Programmingâ€”not promptingâ€”Foundation Models
   * Dlaczego to waÅ¼ne: To najwaÅ¼niejsza zmiana w 2024/2025. Zamiast rÄ™cznie cyzelowaÄ‡ tekst promptu, definiujesz moduÅ‚y logiczne (podobnie jak w PyTorch), a framework sam "kompiluje" i optymalizuje prompty pod dany model.
   * Kluczowe wnioski:
     * Separacja logiki od tekstu: Logika programu jest oddzielona od parametrÃ³w tekstowych (promptÃ³w).
     * Auto-optymalizacja: DSPy potrafi automatycznie dobraÄ‡ few-shot examples (przykÅ‚ady uczÄ…ce) do promptu, maksymalizujÄ…c wynik na zbiorze testowym.
     * SkalowalnoÅ›Ä‡: Pozwala budowaÄ‡ potÄ™Å¼ne potoki (pipelines) przetwarzania tekstu bez rÄ™cznego poprawiania promptÃ³w przy kaÅ¼dej zmianie modelu.
2. RAG Nowej Generacji: GraphRAG vs Vector RAG
Jak LLM analizuje teksty? Wektory sÄ… Å›wietne do wyszukiwania podobieÅ„stw, ale sÅ‚abe w Å‚Ä…czeniu kropek. Tu wchodzi GraphRAG.
 * Microsoft Research: GraphRAG - Unlocking LLM discovery on narrative private data
   * Kluczowe wnioski:
     * Problem "Globalnych PytaÅ„": ZwykÅ‚y RAG (wektorowy) fatalnie radzi sobie z pytaniami typu "Jakie sÄ… gÅ‚Ã³wne motywy w tym zbiorze dokumentÃ³w?".
     * RozwiÄ…zanie: GraphRAG tworzy graf wiedzy (Knowledge Graph) z dokumentÃ³w. LLM "chodzi" po grafie, widzÄ…c powiÄ…zania miÄ™dzy encjami (osobami, firmami, pojÄ™ciami), ktÃ³re w tekÅ›cie sÄ… odlegÅ‚e.
     * SkutecznoÅ›Ä‡: Drastyczna poprawa jakoÅ›ci odpowiedzi przy analizie caÅ‚ych korpusÃ³w danych (holistyczna analiza), a nie tylko wyszukiwaniu fragmentÃ³w.
3. Psychologia Modelu: "Lost in the Middle" i Architektura Kontekstu
Gdzie umieszczaÄ‡ kluczowe informacje, aby zmaksymalizowaÄ‡ skutecznoÅ›Ä‡ (Recall).
 * Lost in the Middle: How Language Models Use Long Contexts (arXiv)
   * Kluczowe wnioski:
     * Krzywa U-ksztaÅ‚tna: Modele najlepiej radzÄ… sobie z informacjami na poczÄ…tku i na koÅ„cu promptu. Informacje w Å›rodku dÅ‚ugiego kontekstu sÄ… czÄ™sto "zapominane" lub ignorowane.
     * Implikacja dla AgentÃ³w: JeÅ›li budujesz prompt z dokumentacjÄ…, najwaÅ¼niejsze instrukcje sterujÄ…ce daj na sam koniec (tuÅ¼ przed odpowiedziÄ… modelu), a definicje rÃ³l na sam poczÄ…tek. "Åšrodek" to miejsce na mniej istotne dane (noise).
4. Nowe Modele "Reasoning" (o1/o3) a Token Cost
WpÅ‚yw nowych modeli "myÅ›lÄ…cych" na konstrukcjÄ™ promptÃ³w.
 * OpenAI o1 System Card & Prompting Advice
   * Kluczowe wnioski:
     * ÅšmierÄ‡ Chain-of-Thought (w prompcie): Dla modeli klasy o1/o3, nie naleÅ¼y stosowaÄ‡ instrukcji "Think step by step". Model robi to sam, generujÄ…c ukryte "tokeny myÅ›lenia" (thinking tokens). Dodawanie tej instrukcji tylko pogarsza wynik i zwiÄ™ksza koszt.
     * CzystoÅ›Ä‡ kontekstu: Te modele wymagajÄ… znacznie prostszych promptÃ³w. Zamiast dawaÄ‡ im instrukcje "jak" majÄ… dojÅ›Ä‡ do wyniku, naleÅ¼y skupiÄ‡ siÄ™ na precyzyjnym opisaniu "co" jest celem i jakie sÄ… ograniczenia (constraints).
     * Format: UÅ¼ywaj delimiterÃ³w (np. Markdown headers, XML tags) bardzo rygorystycznie â€“ te modele sÄ… hiper-czuÅ‚e na strukturÄ™.
5. Benchmarkowanie i Ewaluacja (LLM-as-a-Judge)
Jak mierzyÄ‡, czy zmiana promptu faktycznie coÅ› daÅ‚a?
 * Ragas: Automated Evaluation for RAG Pipelines
   * Kluczowe wnioski:
     * Metryki syntetyczne: Zamiast ludzkiej oceny, uÅ¼ywa siÄ™ innego LLM do oceny:
       * Faithfulness: Czy odpowiedÅº wynika z kontekstu (walka z halucynacjami)?
       * Answer Relevance: Czy odpowiedÅº faktycznie dotyczy pytania?
     * Zastosowanie: NiezbÄ™dne przy refaktoryzacji promptÃ³w. Nigdy nie zmieniaj promptu w systemie produkcyjnym bez przepuszczenia go przez framework ewaluacyjny typu Ragas.
Synteza Techniczna dla Agenta
| Koncepcja | Stare podejÅ›cie (Legacy) | Nowe podejÅ›cie (2025 Standard) | Zysk |
|---|---|---|---|
| Tworzenie PromptÃ³w | RÄ™czne pisanie tekstÃ³w (Strings) | DSPy (Kompilowane moduÅ‚y) | SkalowalnoÅ›Ä‡, Auto-optymalizacja |
| Baza Wiedzy (RAG) | Tylko Wektory (Similarity Search) | GraphRAG (Wektory + Grafy Wiedzy) | Rozumienie relacji i podsumowaÅ„ |
| DÅ‚ugi Kontekst | Wrzucanie wszystkiego jak leci | Optymalizacja "U-Curve" | WyÅ¼szy Recall (pamiÄ™Ä‡) |
| Logika | Wymuszanie CoT w prompcie | Reasoning Models (o1) + Prosty prompt | Lepsze wnioskowanie, mniej inÅ¼ynierii |

---

To Å›wietna decyzja. Zastosowanie architektury opartej na Krzywej U (U-Curve Optimization) jest najprostszÄ… metodÄ… na natychmiastowe zwiÄ™kszenie "inteligencji" modelu bez zmiany samego modelu.
PoniÅ¼ej przygotowaÅ‚em Szablon Struktury Kontekstu (Master Context Template) w formacie Markdown. Jest on zaprojektowany tak, abyÅ› mÃ³gÅ‚ go uÅ¼ywaÄ‡ jako "pojemnika" na swoje projekty.
MoÅ¼esz go traktowaÄ‡ jako jeden duÅ¼y plik .md, ktÃ³ry wklejasz do okna czatu lub przesyÅ‚asz via API.
ğŸ§¬ Architektura Pliku: PROJECT_MASTER_CONTEXT.md
Ten szablon wykorzystuje XML Tags do separacji danych (wg zaleceÅ„ Anthropic) oraz Sandwich Strategy (kluczowe instrukcje na gÃ³rze i na dole) dla przeciwdziaÅ‚ania efektowi "Lost in the Middle".
# 0. META-METADATA (Primacy Effect Zone)
<system_role>
JesteÅ› Ekspertem Architektury Systemowej AI. Twoim celem jest analiza poniÅ¼szych dokumentÃ³w i wygenerowanie rozwiÄ…zania zgodnego z ograniczeniami.
</system_role>

<critical_constraints>
1. NIE wymyÅ›laj faktÃ³w (No Hallucinations). Opieraj siÄ™ tylko na dostarczonym kontekÅ›cie.
2. OdpowiedÅº musi byÄ‡ w formacie JSON (jeÅ›li wymagane) lub Markdown.
3. Ignoruj informacje starsze niÅ¼ rok 2023, jeÅ›li wystÄ™pujÄ… sprzecznoÅ›ci.
</critical_constraints>

---

# 1. KNOWLEDGE BASE (The "Middle" / Trough Zone)
<project_context>

## 1.1 Definicje Projektowe
<documents>
    <doc id="specyfikacja_techniczna">
    [TU WKLEJ TREÅšÄ† DOKUMENTU LUB LINK DO TREÅšCI]
    *WskazÃ³wka: UÅ¼ywaj list punktowanych, sÄ… Å‚atwiejsze do parsowania niÅ¼ Å›ciana tekstu.*
    </doc>

    <doc id="baza_wiedzy_faq">
    [TU WKLEJ FAQ LUB ZASADY BIZNESOWE]
    </doc>
</documents>

## 1.2 Dane Referencyjne (Code/Data)
<code_repository>
    <file name="main.py" language="python">
    [TU WKLEJ KLUCZOWE FRAGMENTY KODU]
    </file>
    
    <file name="schema.json">
    [TU WKLEJ STRUKTURÄ˜ DANYCH]
    </file>
</code_repository>

</project_context>

---

# 2. IMMEDIATE INSTRUCTION (Recency Bias Zone)
<task_execution>

### Twoje Zadanie:
Na podstawie powyÅ¼szych dokumentÃ³w w sekcji <project_context>, wykonaj analizÄ™ ryzyka dla nowego moduÅ‚u pÅ‚atnoÅ›ci.

### Wymagany Format WyjÅ›cia (Output Format):
<output_rules>
- UÅ¼yj formatu Markdown z nagÅ‚Ã³wkami.
- Wypisz listÄ™ w formacie: [Ryzyko] - [PrawdopodobieÅ„stwo] - [Mitygacja].
- Na koÅ„cu dodaj blok kodu JSON z podsumowaniem.
</output_rules>

### Chain of Thought (MyÅ›l krok po kroku):
1. Najpierw przeanalizuj `specyfikacja_techniczna` pod kÄ…tem bezpieczeÅ„stwa.
2. NastÄ™pnie sprawdÅº `main.py` pod kÄ…tem walidacji danych.
3. Dopiero wtedy wygeneruj odpowiedÅº.

ROZPOCZNIJ ANALIZÄ˜ TERAZ.
</task_execution>

Dlaczego ta struktura dziaÅ‚a skuteczniej? Analiza techniczna
 * Tagi XML (<tag>):
   * LLM traktuje tagi XML jako "twarde granice". DziÄ™ki temu nie myli instrukcji ("zrÃ³b to") z treÅ›ciÄ… dokumentu ("w dokumencie napisano: zrÃ³b to"). To drastycznie redukuje tzw. prompt injection pÅ‚ynÄ…cy z wÅ‚asnych danych.
 * NagÅ‚Ã³wki Markdown (#, ##):
   * LLM "widzi" strukturÄ™ dokumentu podobnie jak drzewo DOM. Jasne nagÅ‚Ã³wki pozwalajÄ… mu szybciej "skoczyÄ‡" do odpowiedniej sekcji w przestrzeni wektorowej (attention mechanism).
 * Metoda Kanapki (Sandwich Method):
   * ZauwaÅ¼, Å¼e <critical_constraints> (ograniczenia) sÄ… na samej gÃ³rze, a <output_rules> (format wyjÅ›cia) na samym dole. Model "wchodzi" w zadanie z zasadami i "wychodzi" z przypomnieniem o formacie. To eliminuje typowy bÅ‚Ä…d, gdzie model zapomina o formacie JSON po przeczytaniu 50 stron tekstu.
 * Jawne wywoÅ‚anie CoT (Chain of Thought):
   * W sekcji koÅ„cowej instrukcja "1. Najpierw przeanalizuj..." wymusza na modelu ustrukturyzowane myÅ›lenie, zanim zacznie pisaÄ‡ finalny tekst.
Jak tego uÅ¼ywaÄ‡ w praktyce?
 * StwÃ³rz plik .md na dysku dla swojego projektu (np. Kontekst_Projektu_X.md).
 * Trzymaj ten plik jako "Å»ywy Dokument". Gdy dochodzÄ… nowe dane, wrzucaj je do sekcji <project_context>.
 * Gdy chcesz porozmawiaÄ‡ z Agentem, kopiujesz caÅ‚oÅ›Ä‡, a w sekcji <task_execution> na dole wpisujesz swoje aktualne pytanie.
 * 
Co mogÄ™ dla Ciebie zrobiÄ‡ teraz?
Skoro mamy juÅ¼ strukturÄ™ danych (Input), warto zadbaÄ‡ o jakoÅ›Ä‡ odpowiedzi (Output).
Czy chciaÅ‚byÅ›, abym przygotowaÅ‚ Szablon Schematu JSON (JSON Schema) dla sekcji <output_rules>, ktÃ³ry wymusi na modelu zwracanie odpowiedzi w formacie idealnym do dalszego przetwarzania przez skrypty lub automatyzacje? (To kluczowe dla AgentÃ³w AI).

â€‹âš™ï¸ Szablon: JSON Schema dla Odpowiedzi Agenta 

â€‹PoniÅ¼szy kod naleÅ¼y umieÅ›ciÄ‡ w sekcji <output_rules> Twojego pliku PROJECT_MASTER_CONTEXT.md. Upewnij siÄ™, Å¼e uÅ¼ywasz modelu LLM, ktÃ³ry wspiera tryb zwracania czystego JSON (np. response_format={"type": "json_object"} w OpenAI/Gemini, lub tool_use/XML w Anthropic).

'''
<JSON_OUTPUT_SCHEMA>
{
    "$schema": "http://json-schema.org/draft-07/schema#",
    "title": "AnalizaRyzkaProjektu",
    "type": "object",
    "description": "Schema do raportowania analizy ryzyka na podstawie dostarczonego kontekstu.",
    "properties": {
        "report_summary": {
            "type": "string",
            "description": "KrÃ³tkie podsumowanie kluczowego wniosku z analizy (maks. 50 sÅ‚Ã³w)."
        },
        "confidence_score": {
            "type": "integer",
            "description": "PewnoÅ›Ä‡ modelu co do poprawnoÅ›ci i kompletnoÅ›ci odpowiedzi (w skali 0 do 100).",
            "minimum": 0,
            "maximum": 100
        },
        "analysis_items": {
            "type": "array",
            "description": "Lista szczegÃ³Å‚owych ustaleÅ„ i zaleceÅ„.",
            "items": {
                "type": "object",
                "properties": {
                    "finding_id": {
                        "type": "string",
                        "description": "Unikalny identyfikator znaleziska (np. RYZK-001)."
                    },
                    "risk_description": {
                        "type": "string",
                        "description": "SzczegÃ³Å‚owy opis zidentyfikowanego ryzyka/ustalenia."
                    },
                    "mitigation_recommendation": {
                        "type": "string",
                        "description": "Konkretne zalecenie majÄ…ce na celu mitygacjÄ™ lub rozwiÄ…zanie problemu."
                    },
                    "source_reference": {
                        "type": "string",
                        "description": "DokÅ‚adne odniesienie do dokumentu lub pliku ÅºrÃ³dÅ‚owego (np. specyfikacja_techniczna, main.py) z sekcji <project_context>."
                    }
                },
                "required": ["finding_id", "risk_description", "mitigation_recommendation", "source_reference"]
            }
        },
        "warnings": {
            "type": "array",
            "description": "Lista ostrzeÅ¼eÅ„ lub obszarÃ³w, w ktÃ³rych brakuje danych w kontekÅ›cie.",
            "items": {
                "type": "string"
            }
        }
    },
    "required": ["report_summary", "confidence_score", "analysis_items"]
}
</JSON_OUTPUT_SCHEMA>
'''

ğŸ¯ Kluczowe korzyÅ›ci dla Agenta â€‹Automatyczna Weryfikacja (Traceability): WymÃ³g pola source_reference (ÅºrÃ³dÅ‚o odniesienia) zmusza model do logicznego Å‚Ä…czenia wniosku z kontekstem, co jest podstawÄ… wysokiej jakoÅ›ci RAG. â€‹Redukcja Post-processingu: Zwracany JSON moÅ¼e byÄ‡ bezpoÅ›rednio zaÅ‚adowany do bazy danych, zautomatyzowanego potoku lub narzÄ™dzia wizualizacyjnego, eliminujÄ…c koniecznoÅ›Ä‡ czyszczenia i parsowania tekstu. â€‹Filtracja na podstawie confidence_score: MoÅ¼esz zaimplementowaÄ‡ zasadÄ™: "JeÅ›li confidence_score jest poniÅ¼ej 80, wyÅ›lij raport do rÄ™cznego przeglÄ…du", zwiÄ™kszajÄ…c niezawodnoÅ›Ä‡ systemu. 


